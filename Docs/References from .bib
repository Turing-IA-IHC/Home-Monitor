% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Fragopanagos2005-fh,
  title    = "Emotion recognition in human-computer interaction",
  author   = "Fragopanagos, N and Taylor, J G",
  abstract = "In this paper, we outline the approach we have developed to
              construct an emotion-recognising system. It is based on guidance
              from psychological studies of emotion, as well as from the nature
              of emotion in its interaction with attention. A neural network
              architecture is constructed to be able to handle the fusion of
              different modalities (facial features, prosody and lexical
              content in speech). Results from the network are given and their
              implications discussed, as are implications for future direction
              for the research.",
  journal  = "Neural Netw.",
  volume   =  18,
  number   =  4,
  pages    = "389--405",
  month    =  may,
  year     =  2005,
  language = "en"
}

@ARTICLE{Castillo2016-lb,
  title   = "Software Architecture for Smart Emotion Recognition and Regulation
             of the Ageing Adult",
  author  = "Castillo, Jos{\'e} Carlos and Castro-Gonz{\'a}lez, {\'A}lvaro and
             Fern{\'a}ndez-Caballero, Antonio and Latorre, Jos{\'e} Miguel and
             Pastor, Jos{\'e} Manuel and Fern{\'a}ndez-Sotos, Alicia and
             Salichs, Miguel A",
  journal = "Cognit. Comput.",
  volume  =  8,
  number  =  2,
  pages   = "357--367",
  year    =  2016
}

@INCOLLECTION{Lozano-Monasor2014-hq,
  title     = "Facial Expression Recognition from Webcam Based on Active Shape
               Models and Support Vector Machines",
  booktitle = "Lecture Notes in Computer Science",
  author    = "Lozano-Monasor, Elena and L{\'o}pez, Mar{\'\i}a T and
               Fern{\'a}ndez-Caballero, Antonio and Vigo-Bustos, Francisco",
  pages     = "147--154",
  year      =  2014
}

@ARTICLE{Sokolova_MV_Serrano-Cuerda_J_Castillo_JC_y_Fernandez-Caballero_A2013-yy,
  title   = "A fuzzy model for human fall detection in infrared video",
  author  = "{Sokolova M.V., Serrano-Cuerda J., Castillo J.C. y
             Fern{\'a}ndez-Caballero, A.}",
  journal = "J. Intell. Fuzzy Syst.",
  volume  =  24,
  number  =  2,
  pages   = "215--228",
  year    =  2013
}

@ARTICLE{Matsubara2012-qq,
  title    = "Real-time stylistic prediction for whole-body human motions",
  author   = "Matsubara, Takamitsu and Hyon, Sang-Ho and Morimoto, Jun",
  abstract = "The ability to predict human motion is crucial in several
              contexts such as human tracking by computer vision and the
              synthesis of human-like computer graphics. Previous work has
              focused on off-line processes with well-segmented data; however,
              many applications such as robotics require real-time control with
              efficient computation. In this paper, we propose a novel approach
              called real-time stylistic prediction for whole-body human
              motions to satisfy these requirements. This approach uses a novel
              generative model to represent a whole-body human motion including
              rhythmic motion (e.g., walking) and discrete motion (e.g.,
              jumping). The generative model is composed of a low-dimensional
              state (phase) dynamics and a two-factor observation model,
              allowing it to capture the diversity of motion styles in humans.
              A real-time adaptation algorithm was derived to estimate both
              state variables and style parameter of the model from
              non-stationary unlabeled sequential observations. Moreover, with
              a simple modification, the algorithm allows real-time adaptation
              even from incomplete (partial) observations. Based on the
              estimated state and style, a future motion sequence can be
              accurately predicted. In our implementation, it takes less than
              15 ms for both adaptation and prediction at each observation. Our
              real-time stylistic prediction was evaluated for human walking,
              running, and jumping behaviors.",
  journal  = "Neural Netw.",
  volume   =  25,
  number   =  1,
  pages    = "191--199",
  month    =  jan,
  year     =  2012,
  language = "en"
}

@ARTICLE{Vinaccia_Alpi2017-hg,
  title   = "Calidad de vida relacionada con la salud, percepci{\'o}n de
             enfermedad, felicidad y emociones negativas en pacientes con
             diagn{\'o}stico de artritis reumatoide",
  author  = "Vinaccia Alpi, Stefano and Alpi, Stefano Vinaccia and Quiceno,
             Japcy Margarita and Lozano, Francy and Romero, Sebastian",
  journal = "Acta Med. Colomb.",
  volume  =  20,
  number  =  1,
  pages   = "49--69",
  year    =  2017
}

@ARTICLE{Megrhi2016-aj,
  title   = "Spatio-temporal action localization and detection for human action
             recognition in big dataset",
  author  = "Megrhi, Sameh and Jmal, Marwa and Souidene, Wided and Beghdadi,
             Azeddine",
  journal = "J. Vis. Commun. Image Represent.",
  volume  =  41,
  pages   = "375--390",
  year    =  2016
}

@INPROCEEDINGS{Rodriguez2011-ax,
  title     = "Density-aware person detection and tracking in crowds",
  booktitle = "2011 International Conference on Computer Vision",
  author    = "Rodriguez, M and Laptev, I and Sivic, J and Audibert, J",
  abstract  = "We address the problem of person detection and tracking in
               crowded video scenes. While the detection of individual objects
               has been improved significantly over the recent years, crowd
               scenes remain particularly challenging for the detection and
               tracking tasks due to heavy occlusions, high person densities
               and significant variation in people's appearance. To address
               these challenges, we propose to leverage information on the
               global structure of the scene and to resolve all detections
               jointly. In particular, we explore constraints imposed by the
               crowd density and formulate person detection as the optimization
               of a joint energy function combining crowd density estimation
               and the localization of individual people. We demonstrate how
               the optimization of such an energy function significantly
               improves person detection and tracking in crowds. We validate
               our approach on a challenging video dataset of crowded scenes.",
  pages     = "2423--2430",
  month     =  nov,
  year      =  2011,
  keywords  = "computer graphics;object detection;object tracking;video signal
               processing;density-aware person detection;density-aware person
               tracking;crowded video scenes;occlusions;high person
               densities;people appearance variation;joint energy
               function;crowd density estimation;individual people
               localization;Head;Detectors;Tracking;Estimation;Cameras;Training;Optimization"
}

@TECHREPORT{2010-xz,
  title       = "A survey of recent advances in face detection",
  author      = "{Zhang, C , \& Zhang,}",
  number      = "MSR-TR-2010-66",
  institution = "Microsoft",
  year        =  2010
}

@INPROCEEDINGS{Xia2012-gq,
  title     = "View invariant human action recognition using histograms of {3D}
               joints",
  booktitle = "2012 {IEEE} Computer Society Conference on Computer Vision and
               Pattern Recognition Workshops",
  author    = "Xia, Lu and Chen, Chia-Chih and Aggarwal, J K",
  year      =  2012
}

@INPROCEEDINGS{Xia2011-fy,
  title     = "Human detection using depth information by Kinect",
  booktitle = "{CVPR} 2011 {WORKSHOPS}",
  author    = "Xia, Lu and Chen, Chia-Chih and Aggarwal, J K",
  year      =  2011
}

@ARTICLE{Kapoor2007-cd,
  title   = "Automatic prediction of frustration",
  author  = "Kapoor, Ashish and Burleson, Winslow and Picard, Rosalind W",
  journal = "Int. J. Hum. Comput. Stud.",
  volume  =  65,
  number  =  8,
  pages   = "724--736",
  year    =  2007
}

@INPROCEEDINGS{Viola2001-mz,
  title           = "Rapid object detection using a boosted cascade of simple
                     features",
  booktitle       = "Proceedings of the 2001 {IEEE} Computer Society Conference
                     on Computer Vision and Pattern Recognition. {CVPR} 2001",
  author          = "Viola, P and Jones, M",
  year            =  2001
}

@ARTICLE{Lozano-Monasor_E_Lopez_M_T_Vigo-Bustos_F_Fernandez-Caballero_A2017-sv,
  title   = "Facial expression recognition in ageing adults: from lab to
             ambient assisted living",
  author  = "{Lozano-Monasor, E., L{\'o}pez, M. T., Vigo-Bustos, F., \&
             Fern{\'a}ndez-Caballero, A.}",
  journal = "J. Ambient Intell. Humaniz. Comput.",
  pages   = "1--12",
  year    =  2017
}

@ARTICLE{Van_Gerven2017-wc,
  title    = "Computational Foundations of Natural Intelligence",
  author   = "van Gerven, Marcel",
  abstract = "New developments in AI and neuroscience are revitalizing the
              quest to understanding natural intelligence, offering insight
              about how to equip machines with human-like capabilities. This
              paper reviews some of the computational principles relevant for
              understanding natural intelligence and, ultimately, achieving
              strong AI. After reviewing basic principles, a variety of
              computational modeling approaches is discussed. Subsequently, I
              concentrate on the use of artificial neural networks as a
              framework for modeling cognitive processes. This paper ends by
              outlining some of the challenges that remain to fulfill the
              promise of machines that show human-like intelligence.",
  journal  = "Front. Comput. Neurosci.",
  volume   =  11,
  pages    = "112",
  month    =  dec,
  year     =  2017,
  keywords = "artificial neural networks; cognition; machine learning; natural
              intelligence; strong AI",
  language = "en"
}

@MISC{Chen2015-sq,
  title   = "A Deep Learning Approach to Human Activity Recognition Based on
             Single Accelerometer",
  author  = "Chen, Yuqing and Xue, Yang",
  journal = "2015 IEEE International Conference on Systems, Man, and
             Cybernetics",
  year    =  2015
}

@ARTICLE{Fukushima1982-wo,
  title    = "Neocognitron: A new algorithm for pattern recognition tolerant of
              deformations and shifts in position",
  author   = "Fukushima, Kunihiko and Miyake, Sei",
  abstract = "Suggested by the structure of the visual nervous system, a new
              algorithm is proposed for pattern recognition. This algorithm can
              be realized with a multilayered network consisting of neuron-like
              cells. The network, ``neocognitron'', is self-organized by
              unsupervised learning, and acquires the ability to recognize
              stimulus patterns according to the differences in their shapes:
              Any patterns which we human beings judge to be alike are also
              judged to be of the same category by the neocognitron. The
              neocognitron recognizes stimulus patterns correctly without being
              affected by shifts in position or even by considerable
              distortions in shape of the stimulus patterns.",
  journal  = "Pattern Recognit.",
  volume   =  15,
  number   =  6,
  pages    = "455--469",
  month    =  jan,
  year     =  1982,
  keywords = "Visual pattern recognition; Deformation-resistant; Unsupervised
              learning; Self-organization; Neural network model; Visual nervous
              system"
}

@ARTICLE{Zhao_L_Gao_X_Tao_D_Li_X2015-sq,
  title   = "A deep structure for human pose estimation",
  author  = "{Zhao, L., Gao, X., Tao, D., \& Li, X.}",
  journal = "Signal Processing",
  volume  =  108,
  pages   = "36--45",
  year    =  2015
}

@INPROCEEDINGS{M_Meshry_and_M_E_Hussein_and_M_Torki2016-go,
  title           = "Linear-time online action detection from {3D} skeletal
                     data using bags of gesturelets",
  booktitle       = "2016 {IEEE} Winter Conference on Applications of Computer
                     Vision ({WACV})",
  author          = "{M. Meshry and M. E. Hussein and M. Torki}",
  pages           = "1--9",
  year            =  2016
}

@BOOK{Lopez2008-rx,
  title     = "Las Redes Neuronales Artificiales",
  author    = "L{\'o}pez, Raquel Fl{\'o}rez and Fern{\'a}ndez, Jos{\'e} Miguel
               Fern{\'a}ndez",
  abstract  = "Los modelos de procesamiento inspirados en la naturaleza
               permiten tratar con informaci{\'o}n masiva, redundante e
               imprecisa, superando muchas limitaciones de las t{\'e}cnicas
               estad{\'\i}sticas tradicionales. Entre estos modelos destacan
               las redes neuronales artificiales, que emulan algunas de las
               caracter{\'\i}sticas del cerebro y aprenden a resolver problemas
               a partir de ejemplos, lo que evita formalizar el conocimiento y
               facilita la resoluci{\'o}n de problemas complejos, como la
               segmentaci{\'o}n de clientes, el diagn{\'o}stico de insolvencias
               o la predicci{\'o}n de series temporales. Este libro introduce
               al lector en el estudio de los modelos de redes neuronales
               artificiales m{\'a}s exitosos. El an{\'a}lisis de su
               arquitectura, estimaci{\'o}n, interpretaci{\'o}n y
               evaluaci{\'o}n constituye una aportaci{\'o}n de particular
               utilidad para los investigadores y profesionales que deseen
               implementar en la pr{\'a}ctica sus propias redes. El texto
               incluye, adem{\'a}s, una aplicaci{\'o}n real de diversos modelos
               neuronales y su comparaci{\'o}n con t{\'e}cnicas
               estad{\'\i}sticas, que permite comprender la utilidad de este
               enfoque y sus aplicaciones pr{\'a}cticas.",
  publisher = "Netbiblo",
  month     =  feb,
  year      =  2008,
  language  = "es"
}

@ARTICLE{Pol_undated-os,
  title  = "\?\`Qu{\'e} son las redes neuronales artificiales? Aplicaciones
            realizadas en el {\'a}mbito de las adicciones",
  author = "Pol, Palmer and Moreno, Monta{\~n}o and J., J"
}

@ARTICLE{Baeza2009-tj,
  title   = "Involuci{\'o}n de la condici{\'o}n f{\'\i}sica por el
             envejecimiento",
  author  = "Baeza, Ana Carbonell and Garc{\'\i}a-Molina, Virginia Aparicio and
             Fern{\'a}ndez, Manuel Delgado",
  journal = "Apunts. Medicina de l'Esport",
  volume  =  44,
  number  =  162,
  pages   = "98--103",
  year    =  2009
}

@ARTICLE{LeCun1998-td,
  title     = "Gradient-based learning applied to document recognition",
  author    = "LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner,
               Patrick and {Others}",
  journal   = "Proc. IEEE",
  publisher = "Taipei, Taiwan",
  volume    =  86,
  number    =  11,
  pages     = "2278--2324",
  year      =  1998
}

@INCOLLECTION{Newell2016-ko,
  title     = "Stacked Hourglass Networks for Human Pose Estimation",
  booktitle = "Lecture Notes in Computer Science",
  author    = "Newell, Alejandro and Yang, Kaiyu and Deng, Jia",
  pages     = "483--499",
  year      =  2016
}

@ARTICLE{Soomro_Khurram_and_Zamir_Amir_Roshan_and_Shah_Mubarak2012-mr,
  title   = "{UCF101}: A dataset of 101 human actions classes from videos in
             the wild",
  author  = "{Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak}",
  journal = "arXiv preprint arXiv:1212.0402",
  year    =  2012
}

@ARTICLE{Arriagada2007-ye,
  title   = "Familias latinoamericanas: cambiantes, diversas y desiguales",
  author  = "Arriagada, I",
  journal = "Papeles de poblaci{\'o}n",
  volume  =  13,
  number  = "(53)",
  pages   = "9--22",
  year    =  2007
}

@ARTICLE{Hubel1962-im,
  title    = "Receptive fields, binocular interaction and functional
              architecture in the cat's visual cortex",
  author   = "Hubel, D H and Wiesel, T N",
  journal  = "J. Physiol.",
  volume   =  160,
  pages    = "106--154",
  month    =  jan,
  year     =  1962,
  keywords = "CEREBRAL CORTEX/physiology",
  language = "en"
}

@INCOLLECTION{Salas2011-rb,
  title     = "People Detection Using Color and Depth Images",
  booktitle = "Lecture Notes in Computer Science",
  author    = "Salas, Joaqu{\'\i}n and Tomasi, Carlo",
  pages     = "127--135",
  year      =  2011
}

@MISC{noauthor_undated-uq,
  title        = "Envejecimiento activo, vida aut{\'o}noma y asistida",
  booktitle    = "http://eshorizonte2020.cdti.es",
  howpublished = "\url{http://eshorizonte2020.cdti.es/index.asp?MP=87&MS=715&MN=2&TR=C&IDR=1986}",
  note         = "Accessed: 2017-NA-NA"
}

@ARTICLE{Kleinsmith2013-hb,
  title   = "Affective Body Expression Perception and Recognition: A Survey",
  author  = "Kleinsmith, Andrea and Bianchi-Berthouze, Nadia",
  journal = "IEEE Transactions on Affective Computing",
  volume  =  4,
  number  =  1,
  pages   = "15--33",
  year    =  2013
}

@ARTICLE{Antonio_Fernandez-Caballero_Arturo_Martinez-Rodrigo_Jose_Manuel_Pastor_Jose_Carlos_Castillo_Elena_Lozano-Monasor_Maria_T_Lopez_Roberto_Zangroniz_Jose_Miguel_Latorre_Alicia_Fernandez-Sotos2016-oa,
  title    = "Smart environment architecture for emotion detection and
              regulation",
  author   = "{Antonio Fern{\'a}ndez-Caballero, Arturo Mart{\'\i}nez-Rodrigo,
              Jos{\'e} Manuel Pastor, Jos{\'e} Carlos Castillo, Elena
              Lozano-Monasor, Mar{\'\i}a T. L{\'o}pez, Roberto Zangr{\'o}niz,
              Jos{\'e} Miguel Latorre, Alicia Fern{\'a}ndez-Sotos}",
  abstract = "This paper introduces an architecture as a proof-of-concept for
              emotion detection and regulation in smart health environments.
              The aim of the proposal is to detect the patient's emotional
              state by analysing his/her physiological signals, facial
              expression and behaviour. Then, the system provides the
              best-tailored actions in the environment to regulate these
              emotions towards a positive mood when possible. The current
              state-of-the-art in emotion regulation through music and
              colour/light is implemented with the final goal of enhancing the
              quality of life and care of the subject. The paper describes the
              three main parts of the architecture, namely ``Emotion
              Detection'', ``Emotion Regulation'' and ``Emotion Feedback
              Control''. ``Emotion Detection'' works with the data captured
              from the patient, whereas ``Emotion Regulation'' offers him/her
              different musical pieces and colour/light settings. ``Emotion
              Feedback Control'' performs as a feedback control loop to assess
              the effect of emotion regulation over emotion detection. We are
              currently testing the overall architecture and the intervention
              in real environments to achieve our final goal.",
  journal  = "J. Biomed. Inform.",
  volume   =  64,
  pages    = "55--73",
  year     =  2016
}

@ARTICLE{Shen2014-zy,
  title    = "Exemplar-based human action pose correction",
  author   = "Shen, Wei and Deng, Ke and Bai, Xiang and Leyvand, Tommer and
              Guo, Baining and Tu, Zhuowen",
  abstract = "The launch of Xbox Kinect has built a very successful computer
              vision product and made a big impact on the gaming industry. This
              sheds lights onto a wide variety of potential applications
              related to action recognition. The accurate estimation of human
              poses from the depth image is universally a critical step.
              However, existing pose estimation systems exhibit failures when
              facing severe occlusion. In this paper, we propose an
              exemplar-based method to learn to correct the initially estimated
              poses. We learn an inhomogeneous systematic bias by leveraging
              the exemplar information within a specific human action domain.
              Furthermore, as an extension, we learn a conditional model by
              incorporation of pose tags to further increase the accuracy of
              pose correction. In the experiments, significant improvements on
              both joint-based skeleton correction and tag prediction are
              observed over the contemporary approaches, including what is
              delivered by the current Kinect system. Our experiments for the
              facial landmark correction also illustrate that our algorithm can
              improve the accuracy of other detection/estimation systems.",
  journal  = "IEEE Trans Cybern",
  volume   =  44,
  number   =  7,
  pages    = "1053--1066",
  month    =  jul,
  year     =  2014,
  language = "en"
}

@MISC{noauthor_undated-vu,
  title        = "Poblaci{\'o}n de 65 a{\~n}os de edad y m{\'a}s (\% del total)
                  | Data",
  abstract     = "Poblaci{\'o}n de 65 a{\~n}os de edad y m{\'a}s (\% del total)
                  from The World Bank: Data",
  howpublished = "
                  \url{http://datos.bancomundial.org/indicador/SP.POP.65UP.TO.ZS
                  }",
  note         = "Accessed: 2017-10-9"
}

@ARTICLE{Vishwakarma2015-pt,
  title   = "Hybrid classifier based human activity recognition using the
             silhouette and cells",
  author  = "Vishwakarma, D K and Kapoor, Rajiv",
  journal = "Expert Syst. Appl.",
  volume  =  42,
  number  =  20,
  pages   = "6957--6965",
  year    =  2015
}

@ARTICLE{Ning2017-sw,
  title   = "{Knowledge-Guided} Deep Fractal Neural Networks for Human Pose
             Estimation",
  author  = "Ning, Guanghan and Zhang, Zhi and He, Zhiquan",
  journal = "IEEE Trans. Multimedia",
  pages   = "1--1",
  year    =  2017
}

@ARTICLE{Yu2015-ju,
  title   = "Human pose recovery by supervised spectral embedding",
  author  = "Yu, Jun and Guo, Yukun and Tao, Dapeng and Wan, Jian",
  journal = "Neurocomputing",
  volume  =  166,
  pages   = "301--308",
  year    =  2015
}

@ARTICLE{Chou_Chia-Jung_and_Chien_Jui-Ting_and_Chen_Hwann-Tzong2017-on,
  title   = "Self Adversarial Training for Human Pose Estimation",
  author  = "{Chou, Chia-Jung and Chien, Jui-Ting and Chen, Hwann-Tzong}",
  journal = "arXiv preprint arXiv:1707.02439",
  year    =  2017
}

@INCOLLECTION{Ikemura2011-ti,
  title     = "{Real-Time} Human Detection Using Relational Depth Similarity
               Features",
  booktitle = "Lecture Notes in Computer Science",
  author    = "Ikemura, Sho and Fujiyoshi, Hironobu",
  pages     = "25--38",
  year      =  2011
}

@INPROCEEDINGS{Shan2014-as,
  title     = "{3D} human action segmentation and recognition using pose
               kinetic energy",
  booktitle = "2014 {IEEE} International Workshop on Advanced Robotics and its
               Social Impacts",
  author    = "Shan, Junjie and Akella, Srinivas",
  year      =  2014
}

@INCOLLECTION{Kapur2005-bz,
  title     = "{Gesture-Based} Affective Computing on Motion Capture Data",
  booktitle = "Lecture Notes in Computer Science",
  author    = "Kapur, Asha and Kapur, Ajay and Virji-Babul, Naznin and
               Tzanetakis, George and Driessen, Peter F",
  pages     = "1--7",
  year      =  2005
}

@ARTICLE{Castro_J_F_i_Izquierdo_S_E1994-fk,
  title   = "Emociones y salud",
  author  = "{Castro, J. F., \& i Izquierdo, S. E.}",
  journal = "Anuario de psicolog{\'\i}a/The UB Journal of psychology",
  volume  =  65,
  pages   = "25--32",
  year    =  1994
}

@MASTERSTHESIS{Mendez_Silva2013-be,
  title  = "Implementaci{\'o}n de un sistema de identificaci{\'o}n de poses en
            im{\'a}genes de rostros",
  author = "M{\'e}ndez Silva, P E",
  year   =  2013
}

@ARTICLE{Lu2014-el,
  title   = "Application of an incremental {SVM} algorithm for on-line human
             recognition from video surveillance using texture and color
             features",
  author  = "Lu, Yanyun and Boukharouba, Khaled and Boon{\ae}rt, Jacques and
             Fleury, Anthony and Lec{\oe}uche, St{\'e}phane",
  journal = "Neurocomputing",
  volume  =  126,
  pages   = "132--140",
  year    =  2014
}

@ARTICLE{Karsh2006-xe,
  title   = "Theories of work-related musculoskeletal disorders: Implications
             for ergonomic interventions",
  author  = "Karsh, B-T",
  journal = "Theoretical Issues in Ergonomics Science",
  volume  =  7,
  number  =  1,
  pages   = "71--88",
  year    =  2006
}

@ARTICLE{Ioannou2005-rv,
  title    = "Emotion recognition through facial expression analysis based on a
              neurofuzzy network",
  author   = "Ioannou, Spiros V and Raouzaiou, Amaryllis T and Tzouvaras,
              Vasilis A and Mailis, Theofilos P and Karpouzis, Kostas C and
              Kollias, Stefanos D",
  abstract = "Extracting and validating emotional cues through analysis of
              users' facial expressions is of high importance for improving the
              level of interaction in man machine communication systems.
              Extraction of appropriate facial features and consequent
              recognition of the user's emotional state that can be robust to
              facial expression variations among different users is the topic
              of this paper. Facial animation parameters (FAPs) defined
              according to the ISO MPEG-4 standard are extracted by a robust
              facial analysis system, accompanied by appropriate confidence
              measures of the estimation accuracy. A novel neurofuzzy system is
              then created, based on rules that have been defined through
              analysis of FAP variations both at the discrete emotional space,
              as well as in the 2D continuous activation-evaluation one. The
              neurofuzzy system allows for further learning and adaptation to
              specific users' facial expression characteristics, measured
              though FAP estimation in real life application of the system,
              using analysis by clustering of the obtained FAP values.
              Experimental studies with emotionally expressive datasets,
              generated in the EC IST ERMIS project indicate the good
              performance and potential of the developed technologies.",
  journal  = "Neural Netw.",
  volume   =  18,
  number   =  4,
  pages    = "423--435",
  month    =  may,
  year     =  2005,
  language = "en"
}

@MISC{noauthor_2018-yz,
  title     = "'Vecino Sallimi', muerte solitaria",
  journal   = "chosun. com",
  publisher = "chosun.com",
  month     =  apr,
  year      =  2018
}

@ARTICLE{Zaki2014-ie,
  title   = "Using automated walking gait analysis for the identification of
             pedestrian attributes",
  author  = "Zaki, Mohamed H and Sayed, Tarek",
  journal = "Transp. Res. Part C: Emerg. Technol.",
  volume  =  48,
  pages   = "16--36",
  year    =  2014
}

@INCOLLECTION{Rojas-Albarracin2010-wi,
  title     = "Skeleton Simplification by Key Points Identification",
  booktitle = "Lecture Notes in Computer Science",
  author    = "Rojas-Albarrac{\'\i}n, Gabriel and Carbajal, Carlos A and
               Fern{\'a}ndez-Caballero, Antonio and L{\'o}pez, Mar{\'\i}a T",
  pages     = "30--39",
  year      =  2010
}

@INCOLLECTION{Fernandez-Caballero2014-ms,
  title     = "Improvement of the Elderly Quality of Life and Care through
               Smart Emotion Regulation",
  booktitle = "Lecture Notes in Computer Science",
  author    = "Fern{\'a}ndez-Caballero, Antonio and Latorre, Jos{\'e} Miguel
               and Pastor, Jos{\'e} Manuel and Fern{\'a}ndez-Sotos, Alicia",
  pages     = "348--355",
  year      =  2014
}

@MISC{Fan2017-bh,
  title   = "A deep neural network for real-time detection of falling humans in
             naturally occurring scenes",
  author  = "Fan, Yaxiang and Levine, Martin D and Wen, Gongjian and Qiu,
             Shaohua",
  journal = "Neurocomputing",
  volume  =  260,
  pages   = "43--58",
  year    =  2017
}

@ARTICLE{Matich2001-gi,
  title   = "Redes Neuronales: Conceptos b{\'a}sicos y aplicaciones",
  author  = "Matich, Dami{\'a}n Jorge",
  journal = "Universidad Tecnol{\'o}gica Nacional, M{\'e}xico",
  year    =  2001
}

@INPROCEEDINGS{He2017-hh,
  title     = "Mask {R-CNN}",
  booktitle = "2017 {IEEE} International Conference on Computer Vision ({ICCV})",
  author    = "He, K and Gkioxari, G and Doll{\'a}r, P and Girshick, R",
  abstract  = "We present a conceptually simple, flexible, and general
               framework for object instance segmentation. Our approach
               efficiently detects objects in an image while simultaneously
               generating a high-quality segmentation mask for each instance.
               The method, called Mask R-CNN, extends Faster R-CNN by adding a
               branch for predicting an object mask in parallel with the
               existing branch for bounding box recognition. Mask R-CNN is
               simple to train and adds only a small overhead to Faster R-CNN,
               running at 5 fps. Moreover, Mask R-CNN is easy to generalize to
               other tasks, e.g., allowing us to estimate human poses in the
               same framework. We show top results in all three tracks of the
               COCO suite of challenges, including instance segmentation,
               bounding-box object detection, and person keypoint detection.
               Without tricks, Mask R-CNN outperforms all existing,
               single-model entries on every task, including the COCO 2016
               challenge winners. We hope our simple and effective approach
               will serve as a solid baseline and help ease future research in
               instance-level recognition. Code will be made available.",
  pages     = "2980--2988",
  month     =  oct,
  year      =  2017,
  keywords  = "feature extraction;image segmentation;object detection;pose
               estimation;conceptually simple framework;bounding-box object
               detection;object mask;Faster R-CNN;called Mask
               R-CNN;high-quality segmentation mask;object instance
               segmentation;Feature extraction;Image segmentation;Object
               detection;Semantics;Quantization (signal);Robustness"
}

@INPROCEEDINGS{Chu2017-sx,
  title     = "Multi-context Attention for Human Pose Estimation",
  booktitle = "2017 {IEEE} Conference on Computer Vision and Pattern
               Recognition ({CVPR})",
  author    = "Chu, Xiao and Yang, Wei and Ouyang, Wanli and Ma, Cheng and
               Yuille, Alan L and Wang, Xiaogang",
  year      =  2017
}

@INPROCEEDINGS{Liu2017-kg,
  title     = "Potential of Convolutional Neural {Network-Based} {2D} Human
               Pose Estimation for {On-Site} Activity Analysis of Construction
               Workers",
  booktitle = "Computing in Civil Engineering 2017",
  author    = "Liu, Meiyin and Han, Sanguk and Lee, Sanghyun",
  year      =  2017
}

@ARTICLE{Reyes2013-ea,
  title   = "Automatic digital biometry analysis based on depth maps",
  author  = "Reyes, Miguel and Clap{\'e}s, Albert and Ram{\'\i}rez, Jos{\'e}
             and Revilla, Juan R and Escalera, Sergio",
  journal = "Comput. Ind.",
  volume  =  64,
  number  =  9,
  pages   = "1316--1325",
  year    =  2013
}

@ARTICLE{Benzer2012-dm,
  title   = "Teachers' Opinions About The Use Of Body Language",
  author  = "Benzer, A",
  journal = "Education",
  volume  =  132,
  number  = "(3)",
  pages   = "467",
  year    =  2012
}

@ARTICLE{Poppe2007-pb,
  title    = "Vision-based human motion analysis: An overview",
  author   = "Poppe, Ronald",
  abstract = "Markerless vision-based human motion analysis has the potential
              to provide an inexpensive, non-obtrusive solution for the
              estimation of body poses. The significant research effort in this
              domain has been motivated by the fact that many application
              areas, including surveillance, Human--Computer Interaction and
              automatic annotation, will benefit from a robust solution. In
              this paper, we discuss the characteristics of human motion
              analysis. We divide the analysis into a modeling and an
              estimation phase. Modeling is the construction of the likelihood
              function, estimation is concerned with finding the most likely
              pose given the likelihood surface. We discuss model-free
              approaches separately. This taxonomy allows us to highlight
              trends in the domain and to point out limitations of the current
              state of the art.",
  journal  = "Comput. Vis. Image Underst.",
  volume   =  108,
  number   =  1,
  pages    = "4--18",
  year     =  2007
}

@ARTICLE{Murad2017-vn,
  title    = "Deep Recurrent Neural Networks for Human Activity Recognition",
  author   = "Murad, Abdulmajid and Pyun, Jae-Young",
  abstract = "Adopting deep learning methods for human activity recognition has
              been effective in extracting discriminative features from raw
              input sequences acquired from body-worn sensors. Although human
              movements are encoded in a sequence of successive samples in
              time, typical machine learning methods perform recognition tasks
              without exploiting the temporal correlations between input data
              samples. Convolutional neural networks (CNNs) address this issue
              by using convolutions across a one-dimensional temporal sequence
              to capture dependencies among input data. However, the size of
              convolutional kernels restricts the captured range of
              dependencies between data samples. As a result, typical models
              are unadaptable to a wide range of activity-recognition
              configurations and require fixed-length input windows. In this
              paper, we propose the use of deep recurrent neural networks
              (DRNNs) for building recognition models that are capable of
              capturing long-range dependencies in variable-length input
              sequences. We present unidirectional, bidirectional, and cascaded
              architectures based on long short-term memory (LSTM) DRNNs and
              evaluate their effectiveness on miscellaneous benchmark datasets.
              Experimental results show that our proposed models outperform
              methods employing conventional machine learning, such as support
              vector machine (SVM) and k-nearest neighbors (KNN). Additionally,
              the proposed models yield better performance than other deep
              learning techniques, such as deep believe networks (DBNs) and
              CNNs.",
  journal  = "Sensors",
  volume   =  17,
  number   =  11,
  month    =  nov,
  year     =  2017,
  keywords = "deep learning; human activity recognition; recurrent neural
              networks",
  language = "en"
}

@INPROCEEDINGS{Yang2017-el,
  title     = "Learning Feature Pyramids for Human Pose Estimation",
  booktitle = "2017 {IEEE} International Conference on Computer Vision ({ICCV})",
  author    = "Yang, Wei and Li, Shuang and Ouyang, Wanli and Li, Hongsheng and
               Wang, Xiaogang",
  year      =  2017
}

@ARTICLE{Kleinsmith2006-vx,
  title   = "Cross-cultural differences in recognizing affect from body posture",
  author  = "Kleinsmith, Andrea and De Silva, P Ravindra and Bianchi-Berthouze,
             Nadia",
  journal = "Interact. Comput.",
  volume  =  18,
  number  =  6,
  pages   = "1371--1389",
  year    =  2006
}

@INPROCEEDINGS{Andriluka2014-wa,
  title     = "{2D} Human Pose Estimation: New Benchmark and State of the Art
               Analysis",
  booktitle = "2014 {IEEE} Conference on Computer Vision and Pattern
               Recognition",
  author    = "Andriluka, Mykhaylo and Pishchulin, Leonid and Gehler, Peter and
               Schiele, Bernt",
  year      =  2014
}

@INPROCEEDINGS{Insafutdinov2017-ne,
  title     = "{ArtTrack}: Articulated {Multi-Person} Tracking in the Wild",
  booktitle = "2017 {IEEE} Conference on Computer Vision and Pattern
               Recognition ({CVPR})",
  author    = "Insafutdinov, E and Andriluka, M and Pishchulin, L and Tang, S
               and Levinkov, E and Andres, B and Schiele, B",
  abstract  = "In this paper we propose an approach for articulated tracking of
               multiple people in unconstrained videos. Our starting point is a
               model that resembles existing architectures for single-frame
               pose estimation but is substantially faster. We achieve this in
               two ways: (1) by simplifying and sparsifying the body-part
               relationship graph and leveraging recent methods for faster
               inference, and (2) by offloading a substantial share of
               computation onto a feed-forward convolutional architecture that
               is able to detect and associate body joints of the same person
               even in clutter. We use this model to generate proposals for
               body joint locations and formulate articulated tracking as
               spatio-temporal grouping of such proposals. This allows to
               jointly solve the association problem for all people in the
               scene by propagating evidence from strong detections through
               time and enforcing constraints that each proposal can be
               assigned to one person only. We report results on a public MPII
               Human Pose benchmark and on a new MPII Video Pose dataset of
               image sequences with multiple people. We demonstrate that our
               model achieves state-of-the-art results while using only a
               fraction of time and is able to leverage temporal information to
               improve state-of-the-art for crowded scenes.",
  pages     = "1293--1301",
  month     =  jul,
  year      =  2017,
  keywords  = "convolution;graph theory;image motion analysis;image
               sequences;pose estimation;recurrent neural nets;tracking;video
               signal processing;MPII Video Pose dataset;ArtTrack;multiperson
               tracking;articulated tracking;unconstrained videos;body-part
               relationship graph;feed-forward convolutional architecture;body
               joints;body joint locations;spatio-temporal grouping;association
               problem;public MPII Human Pose benchmark;temporal
               information;inference;articulated multi-person
               tracking;single-frame pose estimation;Proposals;Videos;Image
               edge detection;Detectors;Pose estimation;Tracking"
}

@ARTICLE{Balista2010-fa,
  title   = "Compact time-independent pattern representation of entire human
             gait cycle for tracking of gait irregularities",
  author  = "Balista, Junius Andr{\'e} F and Soriano, Maricor N and Saloma,
             Caesar A",
  journal = "Pattern Recognit. Lett.",
  volume  =  31,
  number  =  1,
  pages   = "20--27",
  year    =  2010
}

@ARTICLE{Luvizon_Diogo_C_and_Tabia_Hedi_and_Picard_David2017-wc,
  title   = "Human Pose Regression by Combining Indirect Part Detection and
             Contextual Information",
  author  = "{Luvizon, Diogo C and Tabia, Hedi and Picard, David}",
  journal = "arXiv preprint arXiv:1710.02322",
  year    =  2017
}

@MISC{Chen2016-nz,
  title   = "{LSTM} Networks for Mobile Human Activity Recognition",
  author  = "Chen, Yuwen and Zhong, Kunhua and Zhang, Ju and Sun, Qilong and
             Zhao, Xueliang",
  journal = "Proceedings of the 2016 International Conference on Artificial
             Intelligence: Technologies and Applications",
  year    =  2016
}

@BOOK{Allison2013-gp,
  title     = "Precarious Japan",
  author    = "Allison, Anne",
  publisher = "Duke University Press",
  pages     = "126--127",
  year      =  2013
}

@ARTICLE{Bianchi-Berthouze_N_Cairns_P_Cox_A_Jennett_C_Kim_W_W2006-cv,
  title   = "On posture as a modality for expressing and recognizing emotions",
  author  = "{Bianchi-Berthouze, N., Cairns, P., Cox, A., Jennett, C., \& Kim,
             W. W}",
  journal = "In Emotion and HCI workshop at BCS HCI London",
  year    =  2006
}

@INPROCEEDINGS{Schwartz2009-ry,
  title     = "Human detection using partial least squares analysis",
  booktitle = "2009 {IEEE} 12th International Conference on Computer Vision",
  author    = "Schwartz, William Robson and Kembhavi, Aniruddha and Harwood,
               David and Davis, Larry S",
  year      =  2009
}

@MISC{Barcelona2016-oh,
  title     = "Nadie ech{\'o} de menos a Teresa",
  author    = "{Barcelona}",
  journal   = "elperiodico",
  publisher = "El Peri{\'o}dico",
  month     =  may,
  year      =  2016
}

@INPROCEEDINGS{Chen2017-ta,
  title     = "Adversarial {PoseNet}: A {Structure-Aware} Convolutional Network
               for Human Pose Estimation",
  booktitle = "2017 {IEEE} International Conference on Computer Vision ({ICCV})",
  author    = "Chen, Yu and Shen, Chunhua and Wei, Xiu-Shen and Liu, Lingqiao
               and Yang, Jian",
  year      =  2017
}

@ARTICLE{Ming-Hsuan_Yang2002-cu,
  title   = "Detecting faces in images: a survey",
  author  = "{Ming-Hsuan Yang} and Yang, Ming-Hsuan and Kriegman, D J and
             Ahuja, N",
  journal = "IEEE Trans. Pattern Anal. Mach. Intell.",
  volume  =  24,
  number  =  1,
  pages   = "34--58",
  year    =  2002
}

@ARTICLE{Patrona2018-mr,
  title   = "Motion analysis: Action detection, recognition and evaluation
             based on motion capture data",
  author  = "Patrona, Fotini and Chatzitofis, Anargyros and Zarpalas, Dimitrios
             and Daras, Petros",
  journal = "Pattern Recognit.",
  volume  =  76,
  pages   = "612--622",
  year    =  2018
}

@MASTERSTHESIS{Rojas_Albarracin2009-pr,
  title  = "Determinaci{\'o}n de comportamiento humano basado en posturas",
  author = "Rojas Albarrac{\'\i}n, Gabriel",
  month  =  sep,
  year   =  2009,
  school = "Universidad de Castilla - La Mancha"
}

@MISC{Onishi2017-go,
  title     = "A Generation in Japan Faces a Lonely Death",
  author    = "Onishi, Norimitsu",
  journal   = "The New York Times",
  publisher = "The New York Times",
  month     =  nov,
  year      =  2017
}

@INPROCEEDINGS{Dalal_undated-mu,
  title           = "Histograms of Oriented Gradients for Human Detection",
  booktitle       = "2005 {IEEE} Computer Society Conference on Computer Vision
                     and Pattern Recognition ({CVPR'05})",
  author          = "Dalal, N and Triggs, B"
}

@ARTICLE{Krogh2008-jz,
  title     = "What are artificial neural networks?",
  author    = "Krogh, Anders",
  abstract  = "Artificial neural networks have been applied to problems ranging
               from speech recognition to prediction of protein secondary
               structure, classification of cancers and gene prediction. How do
               they work and what might they be good for?",
  journal   = "Nat. Biotechnol.",
  publisher = "Nature Publishing Group",
  volume    =  26,
  number    =  2,
  pages     = "195",
  month     =  feb,
  year      =  2008,
  language  = "en"
}

@ARTICLE{Zeng2014-il,
  title   = "Silhouette-based gait recognition via deterministic learning",
  author  = "Zeng, Wei and Wang, Cong and Yang, Feifei",
  journal = "Pattern Recognit.",
  volume  =  47,
  number  =  11,
  pages   = "3568--3584",
  year    =  2014
}

@MISC{Redaccion2018-tx,
  title     = "La soledad, un mal contempor{\'a}neo mundial que en Reino Unido
               ahora es asunto de Estado - {BBC} News Mundo",
  author    = "{Redacci{\'o}n}",
  journal   = "BBC News",
  publisher = "BBC",
  month     =  jan,
  year      =  2018
}

@ARTICLE{Gonzalez_S_Sedano_J_Villar_J_R_Corchado_E_Herrero_A_Baruque_B2015-uf,
  title   = "Features and models for human activity recognition",
  author  = "{Gonz{\'a}lez, S., Sedano, J., Villar, J. R., Corchado, E.,
             Herrero, {\'A}., \& Baruque, B.}",
  journal = "Neurocomputing",
  year    =  2015
}

@MISC{Google_Inc_undated-ny,
  title        = "tensorflow",
  booktitle    = "tensorflow",
  author       = "{Google Inc.}",
  howpublished = "\url{https://www.tensorflow.org}",
  note         = "Accessed: 2019-4-19"
}
